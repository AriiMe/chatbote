# OLLAMA REST API

Zuerst installiere Ollama aus dem offiziellen [Github-Repository](https://github.com/ollama/ollama).

Als nächstes benötigst du ein Modell. Du kannst auf ihrer [Website](https://ollama.com/models) nachsehen, welche Modelle verfügbar sind(Überprüfe vor der Installation ob dein System die erforderlichen Voraussetzungen erfüllt). Lade das gewünschte Modell herunter und führe dann folgenden Befehl aus:

```bash
    ollama pull llama3.2
```
Danach kannst du Ollama mit folgendem Befehl starten:

```bash 
    ollama run llama3.2
```

In diesem Beispiel verwenden wir das Modell llama3.2